import argparse
import torch
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import matplotlib.dates as mdates

from config import (
    DEVICE, N_AGENTS, WINDOW_SIZE
)
from data_processor import DataProcessor
from environment import MARLStockEnv
from qmix_model import QMIX_Learner

# --- ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê·¸ë˜í”„ í•¨ìˆ˜ ---
def plot_backtest_results(portfolio_values, daily_pnls, test_prices, initial_capital):
    """ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ ì‹œê°í™”í•˜ëŠ” í•¨ìˆ˜ (PnL ê¸°ì¤€)"""
    dates = test_prices.index[:len(portfolio_values)]
    
    # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
    returns = pd.Series(daily_pnls) / initial_capital
    
    # Sharpe Ratio
    sharpe = (returns.mean() / (returns.std() + 1e-9)) * np.sqrt(252)
    
    # Sortino Ratio (í•˜ë°© ë³€ë™ì„±ë§Œ ê³ ë ¤)
    downside_returns = returns[returns < 0]
    downside_std = downside_returns.std() if len(downside_returns) > 0 else 1e-9
    sortino = (returns.mean() / (downside_std + 1e-9)) * np.sqrt(252)
    
    # MDD (Maximum Drawdown)
    cumulative = np.array(portfolio_values)
    running_max = np.maximum.accumulate(cumulative)
    drawdown = (cumulative - running_max) / running_max
    mdd = drawdown.min() * 100
    
    # PnL ê³„ì‚° (ëˆ„ì  ì†ìµ)
    qmix_pnl = np.array(portfolio_values) - initial_capital
    
    # Buy & Hold PnL ê³„ì‚°
    kospi_start = test_prices.iloc[0]
    shares_bought = initial_capital / kospi_start
    buyhold_values = [shares_bought * price for price in test_prices.iloc[:len(portfolio_values)]]
    buyhold_pnl = np.array(buyhold_values) - initial_capital
    
    # KOSPI ì§€ìˆ˜ PnL (ì§€ìˆ˜ ìì²´ì˜ ë³€í™”)
    kospi_index_pnl = (test_prices.iloc[:len(portfolio_values)] - kospi_start).values
    kospi_index_pnl_normalized = (kospi_index_pnl / kospi_start) * initial_capital
    
    # ê·¸ë˜í”„ ìƒì„±
    fig, ax = plt.subplots(figsize=(14, 8))
    
    # ì œëª©ê³¼ ì„±ê³¼ ì§€í‘œ
    final_qmix_pnl = qmix_pnl[-1]
    final_buyhold_pnl = buyhold_pnl[-1]
    title = f'QMIX 4-Agent ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ (PnL ë¹„êµ)\nì´ˆê¸°ìê¸ˆ: {initial_capital:,.0f}ì› | QMIX PnL: {final_qmix_pnl:,.0f}ì› | Buy&Hold PnL: {final_buyhold_pnl:,.0f}ì›'
    fig.suptitle(title, fontsize=14, fontweight='bold', y=0.98)
    
    # QMIX Agent PnL
    ax.plot(dates, qmix_pnl, label='QMIX Agent', color='#2E86AB', linewidth=2.5, zorder=3)
    
    # Buy & Hold PnL
    ax.plot(dates, buyhold_pnl, label='Buy & Hold (ì‚¼ì„±ì „ì)', color='#A23B72', linewidth=2, linestyle='--', alpha=0.8, zorder=2)
    
    # KOSPI ì§€ìˆ˜ PnL
    ax.plot(dates, kospi_index_pnl_normalized, label='KOSPI ì§€ìˆ˜', color='#F18F01', linewidth=2, linestyle='-.', alpha=0.7, zorder=2)
    
    # ì†ìµ 0 ê¸°ì¤€ì„ 
    ax.axhline(y=0, color='gray', linestyle=':', linewidth=1.5, alpha=0.5, label='ì†ìµ 0')
    
    # ì–‘ìˆ˜/ìŒìˆ˜ ì˜ì—­ ìƒ‰ì¹ 
    ax.fill_between(dates, 0, qmix_pnl, where=(qmix_pnl >= 0), alpha=0.1, color='green', interpolate=True)
    ax.fill_between(dates, 0, qmix_pnl, where=(qmix_pnl < 0), alpha=0.1, color='red', interpolate=True)
    
    # ì¶• ì„¤ì •
    ax.set_xlabel('ë‚ ì§œ', fontsize=12, fontweight='bold')
    ax.set_ylabel('ëˆ„ì  ì†ìµ (PnL, ì›)', fontsize=12, fontweight='bold')
    ax.legend(loc='best', fontsize=11, framealpha=0.9)
    ax.grid(True, alpha=0.3, linestyle='--')
    
    # Yì¶• í¬ë§· (ë°±ë§Œ ì› ë‹¨ìœ„)
    ax.yaxis.set_major_formatter(plt.FuncFormatter(lambda x, p: f'{x/1e6:.1f}M'))
    
    # Xì¶• í¬ë§· (2ê°œì›” ê°„ê²©)
    ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m'))
    ax.xaxis.set_major_locator(mdates.MonthLocator(interval=2))
    plt.setp(ax.xaxis.get_majorticklabels(), rotation=45, ha='right')
    
    # ì„±ê³¼ ì§€í‘œ í…ìŠ¤íŠ¸ ë°•ìŠ¤
    textstr = f'Sharpe: {sharpe:.3f}\nSortino: {sortino:.3f}\nMDD: {mdd:.2f}%'
    props = dict(boxstyle='round', facecolor='wheat', alpha=0.5)
    ax.text(0.02, 0.98, textstr, transform=ax.transAxes, fontsize=10,
            verticalalignment='top', bbox=props)
    
    plt.tight_layout()
    plt.savefig('backtest_results.png', dpi=300, bbox_inches='tight')
    plt.close()
    
    return sharpe, sortino, mdd

# --- 4ê°œ ì—ì´ì „íŠ¸ì˜ ì‹ í˜¸ ë³€í™˜ ---
def convert_joint_action_to_signal(joint_action, action_map):
    action_to_score = {"Long": 1, "Hold": 0, "Short": -1}
    score = sum(action_to_score[action_map[a]] for a in joint_action)
    
    if score >= 3:
        return "ì ê·¹ ë§¤ìˆ˜"
    elif score == 2 or score == 1:
        return "ë§¤ìˆ˜"
    elif score == 0:
        return "ë³´ìœ "
    elif score == -1 or score == -2:
        return "ë§¤ë„"
    elif score <= -3:
        return "ì ê·¹ ë§¤ë„"
    return "ë³´ìœ "

# --- AI ì„¤ëª… ìƒì„± ---
def generate_ai_explanation(final_signal, agent_analyses):
    all_importances = {}
    for _, _, importance_list in agent_analyses:
        for feature, imp in importance_list:
            all_importances[feature] = all_importances.get(feature, 0.0) + imp
            
    sorted_features = sorted(all_importances.items(), key=lambda item: item[1], reverse=True)
    
    explanation = f"AIê°€ '{final_signal}'ì„ ê²°ì •í•œ ì£¼ëœ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n\n"
    
    if not sorted_features:
        return explanation + "ë°ì´í„° ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤."
        
    top_feature_1 = sorted_features[0][0]
    explanation += f"  1. '{top_feature_1}' ì§€í‘œì˜ ìµœê·¼ ì›€ì§ì„ì„ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í–ˆìŠµë‹ˆë‹¤.\n"
    
    if len(sorted_features) > 1:
        top_feature_2 = sorted_features[1][0]
        explanation += f"  2. '{top_feature_2}' ì§€í‘œê°€ 2ìˆœìœ„ë¡œ ê²°ì •ì— ì˜í–¥ì„ ë¯¸ì³¤ìŠµë‹ˆë‹¤.\n"
        
    if len(sorted_features) > 2:
        top_feature_3 = sorted_features[2][0]
        explanation += f"  3. ë§ˆì§€ë§‰ìœ¼ë¡œ '{top_feature_3}' ì§€í‘œë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤.\n"
        
    return explanation

# --- UI ì¶œë ¥ í•¨ìˆ˜ ---
def print_ui_output(final_signal, ai_explanation, current_indicators, best_q_total_value):
    print("\n\n=============================================")
    print("      [ ğŸ“± ë¦¬ë¸Œë¦¬ AI ë¶„ì„ ê²°ê³¼ (ì‚¼ì„±ì „ì) ]")
    print("=============================================")
    
    print("\n--- 1. AI ìµœì¢… ì‹ í˜¸ ---")
    print(f"    {final_signal}")
    print(f"    (ì˜ˆìƒ íŒ€ Q-Value: {best_q_total_value:.4f})")
    
    print("\n--- 2. AI ì„¤ëª… ---")
    print(ai_explanation)
    
    print("\n--- 3. ê¸°ìˆ ì  ë¶„ì„ ìƒì„¸ (ìµœì¢…ì¼ ê¸°ì¤€) ---")
    print("    (AIê°€ ì…ìˆ˜í•˜ì—¬ ë¶„ì„í•œ ì›ë³¸ ë°ì´í„°ì…ë‹ˆë‹¤.)\n")
    technical_indicators = [
        'SMA20', 'MACD', 'MACD_Signal', 'RSI', 'Stoch_K', 'Stoch_D', 
        'ATR', 'Bollinger_B', 'VIX'
    ]
    fundamental_indicators = ['ROA', 'DebtRatio', 'AnalystRating']
    
    for indicator in technical_indicators:
        if indicator in current_indicators:
            print(f"    - {indicator:<13}: {current_indicators[indicator]:.2f}")
            
    print("\n    (í€ë”ë©˜íƒˆ ë° ê¸°íƒ€ ë°ì´í„°)\n")
    for indicator in fundamental_indicators:
         if indicator in current_indicators:
            print(f"    - {indicator:<13}: {current_indicators[indicator]:.2f}")
        
    print("=============================================")

# --- ë©”ì¸ ë°±í…ŒìŠ¤íŠ¸ í•¨ìˆ˜ ---
def main():
    parser = argparse.ArgumentParser(description="QMIX Stock Trading Backtest (Load Trained Model)")
    parser.add_argument('--capital', type=float, default=10000000, help="íˆ¬ì ê¸ˆì•¡ (ì›)")
    parser.add_argument('--model', type=str, default='qmix_model.pth', help="í•™ìŠµëœ ëª¨ë¸ íŒŒì¼ ê²½ë¡œ")
    args = parser.parse_args()
    
    CAPITAL = args.capital
    MODEL_PATH = args.model
    
    print(f"\n=== ë°±í…ŒìŠ¤íŠ¸ ì„¤ì • ===")
    print(f"íˆ¬ì ê¸ˆì•¡: {CAPITAL:,.0f}ì›")
    print(f"ëª¨ë¸ íŒŒì¼: {MODEL_PATH}")
    print(f"ì‚¬ìš© ì¥ì¹˜: {DEVICE}")

    # ë°ì´í„° ë¡œë“œ
    processor = DataProcessor()
    (features_unnormalized_df, prices_df, feature_names,
     agent_0_cols, agent_1_cols, agent_2_cols, agent_3_cols) = processor.process()

    # ë°±í…ŒìŠ¤íŒ… ê¸°ê°„: ë§ˆì§€ë§‰ 1ë…„ (252 ê±°ë˜ì¼)
    total_days = len(features_unnormalized_df)
    test_days = 252
    split_idx = total_days - test_days
    
    if split_idx < WINDOW_SIZE * 2:
        print("ì˜¤ë¥˜: ë°ì´í„°ê°€ ë„ˆë¬´ ì ì–´ ë°±í…ŒìŠ¤íŠ¸ê°€ ë¶ˆê°€ëŠ¥í•©ë‹ˆë‹¤.")
        return

    train_features_unnorm = features_unnormalized_df.iloc[:split_idx]
    test_features_unnorm = features_unnormalized_df.iloc[split_idx:]
    test_prices = prices_df.iloc[split_idx:]
    
    print(f"\n--- ë°ì´í„° ë¶„í•  ì •ë³´ ---")
    print(f"ì „ì²´ ë°ì´í„°: {total_days}ì¼")
    print(f"ë°±í…ŒìŠ¤íŒ… ë°ì´í„°: {len(test_features_unnorm)}ì¼ ({test_prices.index[0]} ~ {test_prices.index[-1]})")

    # ì •ê·œí™”
    train_features, test_features = processor.normalize_data(train_features_unnorm, test_features_unnorm)

    # í™˜ê²½ ìƒì„±
    test_env = MARLStockEnv(
        test_features, test_prices, 
        agent_0_cols, agent_1_cols, agent_2_cols, agent_3_cols,
        n_agents=N_AGENTS, window_size=WINDOW_SIZE
    )
    
    obs_dims_list = [
        test_env.observation_dim_0,
        test_env.observation_dim_1,
        test_env.observation_dim_2,
        test_env.observation_dim_3
    ]
    state_dim = test_env.state_dim
    action_dim = test_env.action_dim

    # í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ
    print(f"\n--- í•™ìŠµëœ ëª¨ë¸ ë¡œë“œ ì¤‘: {MODEL_PATH} ---")
    learner = QMIX_Learner(obs_dims_list, action_dim, state_dim, DEVICE)
    learner.load_model(MODEL_PATH)

    # í¬íŠ¸í´ë¦¬ì˜¤ ì´ˆê¸°í™”
    user_portfolio = {
        'capital': CAPITAL,
        'positions': [0] * N_AGENTS,
        'entry_prices': [0.0] * N_AGENTS,
        'shares': 0
    }

    print("\n--- ë°±í…ŒìŠ¤íŠ¸ ìˆ˜í–‰ ì¤‘ ---")
    print(f"--- ì´ˆê¸° íˆ¬ì ê¸ˆì•¡: {CAPITAL:,.0f}ì› ---")
        
    obs_dict, info = test_env.reset(initial_portfolio=user_portfolio)
    global_state = info["global_state"]
    all_team_rewards = []
    all_raw_pnls = []
    portfolio_values = [CAPITAL]
    current_step = 0
    
    while current_step < test_env.max_steps:
        actions_dict = learner.select_actions(obs_dict, 0.0)  # Epsilon = 0.0 (íƒí—˜ ì—†ìŒ)
        obs_dict, rewards_dict, dones_dict, _, info = test_env.step(actions_dict)
        all_team_rewards.append(rewards_dict['agent_0'])
        all_raw_pnls.append(info["raw_pnl"])
        portfolio_values.append(info["portfolio_value"])
        global_state = info["global_state"]
        current_step += 1
        if dones_dict['__all__']:
            break
    
    final_portfolio_value = portfolio_values[-1]
    final_shares = info["shares"]
    final_cash = info["cash"]

    print("\n--- ë°±í…ŒìŠ¤íŠ¸ ì„±ëŠ¥ ì§€í‘œ ---")
    test_days_actual = len(all_team_rewards)
    if test_days_actual > 0:
        all_rewards_series = pd.Series(all_team_rewards)
        all_raw_pnls_series = pd.Series(all_raw_pnls)
        
        total_pnl = all_raw_pnls_series.sum()
        daily_avg_pnl = all_raw_pnls_series.mean()
        daily_std = all_rewards_series.std() + 1e-9
        sharpe_ratio = (all_rewards_series.mean() / daily_std) * np.sqrt(252)
        win_days = (all_raw_pnls_series > 0).sum()
        win_rate = (win_days / test_days_actual) * 100.0
        
        total_return_pct = ((final_portfolio_value - CAPITAL) / CAPITAL) * 100
        
        print(f"    - ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„    : {test_days_actual} ì¼")
        print(f"    - ì´ˆê¸° íˆ¬ì ê¸ˆì•¡   : {CAPITAL:,.0f} ì›")
        print(f"    - ìµœì¢… í¬íŠ¸í´ë¦¬ì˜¤  : {final_portfolio_value:,.0f} ì›")
        print(f"    - ë³´ìœ  ì£¼ì‹        : {final_shares} ì£¼")
        print(f"    - ë³´ìœ  í˜„ê¸ˆ        : {final_cash:,.0f} ì›")
        print(f"    - ëˆ„ì  ìˆ˜ìµ(PnL)   : {total_pnl:,.0f} ì› ({total_return_pct:+.2f}%)")
        print(f"    - ì¼ í‰ê·  ìˆ˜ìµ     : {daily_avg_pnl:,.0f} ì›")
        print(f"    - ì¼ ìˆ˜ìµ ë³€ë™ì„±   : {daily_std:.4f}")
        print(f"    - ìƒ¤í”„ ë¹„ìœ¨ (ì—°í™˜ì‚°): {sharpe_ratio:.3f}")
        print(f"    - ìŠ¹ë¥  (ì¼ë³„)      : {win_rate:.2f}% ({win_days}/{test_days_actual}ì¼)")
        
        # ê·¸ë˜í”„ ìƒì„±
        print("\n--- ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ ê·¸ë˜í”„ ìƒì„± ì¤‘ ---")
        graph_sharpe, graph_sortino, graph_mdd = plot_backtest_results(
            portfolio_values, all_raw_pnls, test_prices, CAPITAL
        )
        print(f"    Sharpe Ratio: {graph_sharpe:.3f}")
        print(f"    Sortino Ratio: {graph_sortino:.3f}")
        print(f"    MDD: {graph_mdd:.2f}%")
        print("    ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: backtest_results.png")
    else:
        print("    - ë°±í…ŒìŠ¤íŠ¸ ê¸°ê°„ì´ 0ì¼ì´ì–´ì„œ ì„±ëŠ¥ì„ ì¸¡ì •í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

    # --- ìµœì¢…ì¼ ìƒì„¸ ë¶„ì„ ---
    print("\n--- ìµœì¢…ì¼ ì˜ˆì¸¡ ìƒì„¸ ë¶„ì„ ---")
    
    final_obs_dict = obs_dict
    action_map = {0: "Long", 1: "Hold", 2: "Short"}
    action_indices = list(action_map.keys())
    
    obs_tensors = [
        torch.FloatTensor(final_obs_dict[f'agent_{i}']).unsqueeze(0).to(DEVICE) 
        for i in range(N_AGENTS)
    ]
    state_tensor = torch.FloatTensor(global_state).unsqueeze(0).to(DEVICE)
    
    q_vals_all_agents = []
    with torch.no_grad():
        for i, agent in enumerate(learner.agents):
            q_vals_all_agents.append(agent.get_q_values(obs_tensors[i]))

    # 4D ê·¸ë¦¬ë“œ ê³„ì‚°
    agent_q_inputs = []
    action_tuples = []
    
    q_vals_0 = q_vals_all_agents[0].squeeze(0)
    q_vals_1 = q_vals_all_agents[1].squeeze(0)
    q_vals_2 = q_vals_all_agents[2].squeeze(0)
    q_vals_3 = q_vals_all_agents[3].squeeze(0)

    for a0_idx in action_indices:
        for a1_idx in action_indices:
            for a2_idx in action_indices:
                for a3_idx in action_indices:
                    q0 = q_vals_0[a0_idx]
                    q1 = q_vals_1[a1_idx]
                    q2 = q_vals_2[a2_idx]
                    q3 = q_vals_3[a3_idx]
                    agent_q_inputs.append(torch.stack([q0, q1, q2, q3]))
                    action_tuples.append((a0_idx, a1_idx, a2_idx, a3_idx))
    
    agent_q_batch = torch.stack(agent_q_inputs) 
    state_batch = state_tensor.repeat(len(action_tuples), 1)

    with torch.no_grad():
        all_q_totals = learner.mixer(agent_q_batch, state_batch)
    
    best_q_total_value = all_q_totals.max().item()
    best_joint_action_idx_flat = all_q_totals.argmax().item()
    best_joint_action_indices = action_tuples[best_joint_action_idx_flat]
    
    # XAI ë¶„ì„
    agent_analyses = []
    feature_names_list = [agent_0_cols, agent_1_cols, agent_2_cols, agent_3_cols]
    n_features_list = [
        test_env.n_features_agent_0, 
        test_env.n_features_agent_1, 
        test_env.n_features_agent_2,
        test_env.n_features_agent_3
    ]
    
    for i, agent in enumerate(learner.agents):
        obs = final_obs_dict[f'agent_{i}']
        agent_feature_names = feature_names_list[i]
        n_features_agent = n_features_list[i]

        action_idx, q_values, importance = agent.get_prediction_with_reason(
            obs, 
            agent_feature_names,
            WINDOW_SIZE, 
            n_features_agent
        )
        agent_analyses.append((action_idx, q_values, importance))
        
    final_signal = convert_joint_action_to_signal(best_joint_action_indices, action_map)
    ai_explanation = generate_ai_explanation(final_signal, agent_analyses)
    
    current_indicator_values = test_features_unnorm.iloc[-1]
    
    # UI í¬ë§·ìœ¼ë¡œ ì¶œë ¥
    print_ui_output(
        final_signal=final_signal,
        ai_explanation=ai_explanation,
        current_indicators=current_indicator_values,
        best_q_total_value=best_q_total_value
    )

if __name__ == "__main__":
    main()
